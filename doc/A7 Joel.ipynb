{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01bbde30",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap>:228: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "import itertools\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import copy\n",
    "import math\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99f8cca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "compas_scores = pd.read_csv('../data/compas-scores-two-years.csv')\n",
    "protected_attributes = ['sex','race']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23de62a1",
   "metadata": {},
   "source": [
    "# Data Cleaning\n",
    "Columns removed\n",
    "- columns with more than 10% of data missing\n",
    "\n",
    "Rows removed\n",
    "- recidivist flag -- is_recid -- to be -1 (when no compas case would be found)\n",
    "- charge date of a defendants Compas scored crime was not within 30 days from when the person was arrested\n",
    "- ordinary traffic offenses -- those with a c_charge_degree of 'O'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd247c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize_numerical_col(num, lim1, lim2):\n",
    "    if num <= lim1:\n",
    "        return 0\n",
    "    elif lim1 < num <= lim2:\n",
    "        return 1\n",
    "    elif num > lim2:\n",
    "        return 2\n",
    "    else:\n",
    "        raise('Invalid row')\n",
    "def categorize_age(age_cat):\n",
    "    if age_cat=='Less than 25':\n",
    "        return 0\n",
    "    elif age_cat=='25 - 45':\n",
    "        return 1\n",
    "    elif age_cat=='Greater than 45':\n",
    "        return 2\n",
    "    else:\n",
    "        raise('Invalid row')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b0c96e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Cleaning\n",
    "\n",
    "# Remove NaNs\n",
    "percent_missing = compas_scores.isnull().sum() * 100 / len(compas_scores)\n",
    "missing_value_df = pd.DataFrame({'column_name': compas_scores.columns,\n",
    "                                 'percent_missing': percent_missing})\n",
    "missing_value_df.sort_values('percent_missing', inplace=True, ascending=False)\n",
    "cols2keep_df = missing_value_df[~(missing_value_df.percent_missing>10)]\n",
    "cols2keep_df_list = cols2keep_df.column_name.tolist()\n",
    "compas_scores_cols_trim = compas_scores[cols2keep_df_list]\n",
    "compas_scores_cols_trim_dropna = compas_scores_cols_trim.dropna()\n",
    "\n",
    "# Apply cleaning descibed in publication of data HERE: https://github.com/propublica/compas-analysis/blob/master/Compas%20Analysis.ipynb\n",
    "compas_df = compas_scores_cols_trim_dropna[(compas_scores_cols_trim_dropna['days_b_screening_arrest']<= 30) & \n",
    "                               (compas_scores_cols_trim_dropna['days_b_screening_arrest']>= -30) &\n",
    "                               (compas_scores_cols_trim_dropna['is_recid']!= -1) &\n",
    "                               (compas_scores_cols_trim_dropna['c_charge_degree']!= \"O\") &\n",
    "                               (compas_scores_cols_trim_dropna['score_text']!= 'N/A') \n",
    "                              ]\n",
    "\n",
    "# Select columns described in https://arxiv.org/abs/2106.00772 only which are (Age, Charge Degree, Gender, Prior Counts, Length Of Stay, race)\n",
    "\n",
    "compas_subset_df = compas_df[[\"sex\",\"age\",\"age_cat\",\"race\",\"priors_count.1\",\"c_charge_degree\",\"c_jail_in\", \"c_jail_out\",\"two_year_recid\"]]\n",
    "\n",
    "\n",
    "# Select only African American and Caucasian\n",
    "compas_subset_df = compas_subset_df[(compas_subset_df[\"race\"]=='Caucasian') |(compas_subset_df[\"race\"]=='African-American') ]\n",
    "\n",
    "# Add length of stay and drop \"c_jail_in\", \"c_jail_out\"\n",
    "\n",
    "compas_subset_df[\"length_stay\"] = pd.to_datetime(compas_subset_df[\"c_jail_out\"]) - pd.to_datetime(compas_subset_df['c_jail_in'])\n",
    "compas_subset_df[\"length_stay\"] = compas_subset_df[\"length_stay\"].apply(lambda x: x.days)\n",
    "compas_subset_df = compas_subset_df.drop(columns = [\"c_jail_in\",\"c_jail_out\"])\n",
    "compas_subset_df['length_stay'] = compas_subset_df[\"length_stay\"].apply(categorize_numerical_col, lim1=7, lim2=90)\n",
    "\n",
    "# Categorize prior counts according to https://arxiv.org/abs/2106.00772 \n",
    "compas_subset_df['priors_count.1'] = compas_subset_df[\"priors_count.1\"].apply(categorize_numerical_col, lim1=0, lim2=3)\n",
    "\n",
    "# Categorize age according to https://arxiv.org/abs/2106.00772\n",
    "compas_subset_df['age_cat'] = compas_subset_df[\"age_cat\"].apply(categorize_age)\n",
    "\n",
    "# Encode categories\n",
    "race_encoder = OrdinalEncoder(dtype='int')\n",
    "compas_subset_df['race']  = race_encoder.fit_transform(compas_subset_df[['race']])\n",
    "\n",
    "sex_encoder = OrdinalEncoder(dtype='int')\n",
    "compas_subset_df['sex']  = sex_encoder.fit_transform(compas_subset_df[['sex']])\n",
    "\n",
    "charge_encoder = OrdinalEncoder(dtype='int')\n",
    "compas_subset_df['c_charge_degree']  = charge_encoder.fit_transform(compas_subset_df[['c_charge_degree']])\n",
    "\n",
    "# Create protected attribute\n",
    "protected_attribute = compas_subset_df[\"race\"]\n",
    "\n",
    "# Target Variable\n",
    "target_variable = compas_subset_df['two_year_recid']\n",
    "\n",
    "# Feature set\n",
    "feature_df = compas_subset_df.drop(['two_year_recid','race','age'], axis=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test, protected_train, protected_test =train_test_split(\n",
    "    feature_df.to_numpy(), target_variable.to_numpy(), protected_attribute.to_numpy(), test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "740acaac",
   "metadata": {},
   "source": [
    "# Implementation of Fairness Feature Selection Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c5fbee30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unique_info_array(data):\n",
    "    \"\"\"Get unique information from input arrays\"\"\"\n",
    "    unique_list = []\n",
    "    \n",
    "    for idx in range(data.shape[1]):\n",
    "        unique_list.append(np.unique(data[:, idx]).tolist())\n",
    "    return unique_list\n",
    "\n",
    "def unique_information_conditional(y, x_s, x_s_c, protected_attr, form=1):\n",
    "    \"\"\"Get unique information from input arrays with conditional probabilities taken into account\"\"\"\n",
    "    \n",
    "    # Using \n",
    "    # IQ(T; R1|R2) = ∑t,r1,r2 QT ,R1,R2 (t, r1, r2) log((QT |R1,R2 (t|r1,r2))/ (QT |R2 (t|r2))) \n",
    "    \n",
    "    if form == 1:\n",
    "\n",
    "        row_count     = len(y)\n",
    "        col_count_y  = y.shape[1]\n",
    "        col_count_xs = x_s.shape[1]\n",
    "        y_xs_protected_attr_xsc = np.concatenate((y, x_s, x_s_c, protected_attr), axis=1)\n",
    "        ui_array = unique_info_array(y_xs_protected_attr_xsc)\n",
    "        ui_array_cat_product = list(itertools.product(*ui_array)) # compute the cartesian product of all arrays\n",
    "    else:\n",
    "        row_count     = len(y)\n",
    "        col_count_y  = x_s.shape[1]\n",
    "        col_count_xs = protected_attr.shape[1]\n",
    "        y_xs_protected_attr_xsc = np.concatenate((x_s, protected_attr, y), axis=1)\n",
    "        ui_array = unique_info_array(y_xs_protected_attr_xsc)\n",
    "        ui_array_cat_product = list(itertools.product(*ui_array)) # compute the cartesian product of all arrays\n",
    "\n",
    "    IQ = 0\n",
    "    for array in ui_array_cat_product:\n",
    "        r1_r2 = len(np.where((y_xs_protected_attr_xsc == array).all(axis=1))[0]) / row_count\n",
    "        r1 = len(np.where((y == array[:col_count_y]).all(axis=1))[0]) / row_count\n",
    "        r2 = len(np.where((y_xs_protected_attr_xsc[:, col_count_y: -col_count_xs] == array[\n",
    "            col_count_y: -col_count_xs]).all(axis=1))[0]) / row_count\n",
    "\n",
    "        try:\n",
    "            r1_given_r2 = len(np.where((y_xs_protected_attr_xsc[:, :col_count_y] == array[:col_count_y]).all(axis=1)\n",
    "                                       & (y_xs_protected_attr_xsc[:, -col_count_xs:]  == array[\n",
    "                                           -col_count_xs:]).all(axis=1))[0]) / len(np.where( \\\n",
    "                (y_xs_protected_attr_xsc[:, -col_count_xs:] == array[-col_count_xs:]).all(axis=1))[0])\n",
    "        except ZeroDivisionError:\n",
    "            r1_given_r2 = 0\n",
    "\n",
    "        if r1_r2 == 0 or r1 == 0 or r2 == 0 or r1_given_r2 == 0:\n",
    "            temp = 0\n",
    "        else:\n",
    "            temp = r1_r2 * np.log(r1_r2 / r2) / r1_given_r2\n",
    "        IQ += np.abs(temp)\n",
    "\n",
    "    return IQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "75d3ccee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unique_information(array_1, array_2):\n",
    "    \"\"\"Get unique information from input arrays\"\"\"\n",
    "    \n",
    "    row_count          = len(array_1)\n",
    "    col_count_array_1  = array_1.shape[1]\n",
    "        \n",
    "    features_combined = np.concatenate((array_1, array_2), axis=1)\n",
    "    ui_array = unique_info_array(features_combined)\n",
    "    ui_array_cat_product = list(itertools.product(*ui_array))\n",
    "    \n",
    "    # Using \n",
    "    # IQ(T; R1|R2) = ∑t,r1,r2 QT ,R1,R2 (t, r1, r2) log((QT |R1,R2 (t|r1,r2))/ (QT |R2 (t|r2))) \n",
    "    \n",
    "    row_count          = len(array_1)\n",
    "    col_count_array_1  = array_1.shape[1]\n",
    "    \n",
    "    IQ = 0\n",
    "    for array in ui_array_cat_product:\n",
    "        r1_r2 = len(np.where((features_combined == array).all(axis=1))[0]) / row_count\n",
    "        r1 = len(np.where((array_1 == array[:col_count_array_1]).all(axis=1))[0]) / row_count\n",
    "        r2 = len(np.where((array_2 == array[col_count_array_1:]).all(axis=1))[0]) / row_count\n",
    "        \n",
    "        if r1_r2 == 0 or r1 == 0 or r2 == 0:\n",
    "            temp = 0\n",
    "        else:\n",
    "            temp = r1_r2 * np.log(r1_r2 / r1) / r1\n",
    "        IQ += np.abs(temp)\n",
    "    return IQ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "691e16cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_subsets(sc):\n",
    "    \"\"\"\n",
    "    Generate all subsets of feature set\n",
    "    \"\"\"\n",
    "    if len(sc) <= 1:\n",
    "        yield sc\n",
    "        yield []\n",
    "    else:\n",
    "        for item in get_feature_subsets(sc[1:]):\n",
    "            yield [sc[0]]+item\n",
    "            yield item\n",
    "            \n",
    "def acc_coef(y, x_s, x_s_c, protected_attr):\n",
    "    return unique_information_conditional(y, x_s, x_s_c, protected_attr)\n",
    "\n",
    "def disc_coef(y, x_s, x_s_c, protected_attr):\n",
    "    return unique_information(y, np.concatenate((x_s, protected_attr), axis=1)) * unique_information(x_s, protected_attr) * unique_information_conditional(y, x_s, x_s_c, protected_attr,form=2)\n",
    "\n",
    "def marginal_acc_coef(y_train, X_train, protected_attr, set_tracker):\n",
    "    \"\"\"compute  marginal accuracy coefficient\"\"\"\n",
    "    num_features = X_train.shape[1]\n",
    "    feat_idx = list(range(num_features))\n",
    "    feat_idx.pop(set_tracker)\n",
    "    feature_subsets = [x for x in get_feature_subsets(feat_idx) if len(x) > 0]\n",
    "    shapley_value =0\n",
    "\n",
    "    for sc_idx in feature_subsets:\n",
    "            coef = math.factorial(len(sc_idx)) * math.factorial(num_features - len(sc_idx) - 1) / math.factorial(num_features)\n",
    "\n",
    "            # Compute v(T ∪ {i}) \n",
    "            idx_xs_ui = copy.deepcopy(sc_idx) # create copy of subset list\n",
    "            idx_xs_ui.append(set_tracker) # append feature index\n",
    "            idx_xsc_ui = list(set(list(range(num_features))).difference(set(idx_xs_ui))) # compliment of x_s\n",
    "            vTU = acc_coef(y_train.reshape(-1, 1), X_train[:, idx_xs_ui], X_train[:, idx_xsc_ui], protected_attr.reshape(-1, 1))\n",
    "\n",
    "             # Compute v(T)\n",
    "            idx_xsc = list(range(num_features))\n",
    "            idx_xsc.pop(set_tracker)\n",
    "            idx_xsc = list(set(idx_xsc).difference(set(sc_idx)))\n",
    "            vT = acc_coef(y_train.reshape(-1, 1), X_train[:, sc_idx], X_train[:, idx_xsc], protected_attr.reshape(-1, 1))\n",
    "\n",
    "            marginal = vTU - vT\n",
    "            shapley_value = shapley_value + coef * marginal\n",
    "    return shapley_value\n",
    "\n",
    "\n",
    "def marginal_disc_coef(y_train, X_train, protected_attr, set_tracker):\n",
    "    \"\"\"compute marginal discrimination coefficient\"\"\"\n",
    "    num_features = X_train.shape[1]\n",
    "    feat_idx = list(range(num_features))\n",
    "    feat_idx.pop(set_tracker)\n",
    "    feature_subsets = [x for x in get_feature_subsets(feat_idx) if len(x) > 0]\n",
    "    shapley_value =0\n",
    "\n",
    "    for sc_idx in feature_subsets:\n",
    "            coef = math.factorial(len(sc_idx)) * math.factorial(num_features - len(sc_idx) - 1) / math.factorial(num_features)\n",
    "\n",
    "            # Compute v(T ∪ {i}) \n",
    "            idx_xs_ui = copy.deepcopy(sc_idx) # create copy of subset list\n",
    "            idx_xs_ui.append(set_tracker) # append feature index\n",
    "            vTU = disc_coef(y_train.reshape(-1, 1), X_train[:, idx_xs_ui],X_train[:, idx_xs_ui], protected_attr.reshape(-1, 1))\n",
    "\n",
    "             # Compute v(T)\n",
    "            idx_xsc = list(range(num_features))\n",
    "            idx_xsc.pop(set_tracker)\n",
    "            idx_xsc = list(set(idx_xsc).difference(set(sc_idx)))\n",
    "            vT = disc_coef(y_train.reshape(-1, 1), X_train[:, sc_idx], X_train[:, sc_idx], protected_attr.reshape(-1, 1))\n",
    "\n",
    "            marginal = vTU - vT\n",
    "            shapley_value = shapley_value + coef * marginal\n",
    "    return shapley_value\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bdb2d380",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.39 s, sys: 99.6 ms, total: 8.49 s\n",
      "Wall time: 8.51 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Discrimation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sex</td>\n",
       "      <td>0.973917</td>\n",
       "      <td>729.645575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Age</td>\n",
       "      <td>1.181441</td>\n",
       "      <td>939.740547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Prior Count</td>\n",
       "      <td>1.229856</td>\n",
       "      <td>982.431358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Charge Degree</td>\n",
       "      <td>1.046473</td>\n",
       "      <td>765.737748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Length of Stay</td>\n",
       "      <td>1.028396</td>\n",
       "      <td>908.017124</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Feature  Accuracy  Discrimation\n",
       "0             sex  0.973917    729.645575\n",
       "1             Age  1.181441    939.740547\n",
       "2     Prior Count  1.229856    982.431358\n",
       "3   Charge Degree  1.046473    765.737748\n",
       "4  Length of Stay  1.028396    908.017124"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# shapley values for accuracy and discrimination\n",
    "shapley_acc = []\n",
    "shapley_disc = []\n",
    "for i in range(5):\n",
    "    acc_i = marginal_acc_coef(y_train, X_train, protected_train, i)\n",
    "    disc_i = marginal_disc_coef(y_train, X_train, protected_train, i)\n",
    "    \n",
    "    \n",
    "    shapley_acc.append(acc_i)\n",
    "    shapley_disc.append(disc_i)\n",
    "\n",
    "# DataFrame to compare shapely values\n",
    "feature_names = [\"sex\", \"Age\", \"Prior Count\", \"Charge Degree\", \"Length of Stay\"]\n",
    "shapley_df = pd.DataFrame(list(zip(feature_names, shapley_acc, shapley_disc)),\n",
    "                          columns=[\"Feature\", \"Accuracy\",'Discrimation'])\n",
    "shapley_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4ab5dde",
   "metadata": {},
   "source": [
    "We observe that Prior count and Age have the strongest discrimatory coefficients but also have the largest impact on the accuracy "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84981d9a",
   "metadata": {},
   "source": [
    "# Prediction model using logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43b32197",
   "metadata": {},
   "source": [
    "We apply a logistic regression to the feature set and observe the impact on accuracy when we eliminate an individual feature and copare this with the discriminatory impact said feature has on the overall model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7d36a7fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Eliminating Feature</th>\n",
       "      <th>Accuracy (%)</th>\n",
       "      <th>Calibration (%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td>66.919431</td>\n",
       "      <td>0.627451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sex</td>\n",
       "      <td>65.876777</td>\n",
       "      <td>1.191410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Age</td>\n",
       "      <td>63.601896</td>\n",
       "      <td>-0.515406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Prior Count</td>\n",
       "      <td>58.578199</td>\n",
       "      <td>6.715219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Charge Degree</td>\n",
       "      <td>67.014218</td>\n",
       "      <td>0.468721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Length of stay</td>\n",
       "      <td>66.161137</td>\n",
       "      <td>1.503268</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Eliminating Feature  Accuracy (%)  Calibration (%)\n",
       "0                None     66.919431         0.627451\n",
       "1                 Sex     65.876777         1.191410\n",
       "2                 Age     63.601896        -0.515406\n",
       "3         Prior Count     58.578199         6.715219\n",
       "4       Charge Degree     67.014218         0.468721\n",
       "5      Length of stay     66.161137         1.503268"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = []\n",
    "calibration = []\n",
    "\n",
    "# Build model testing impact of each feature on model accuracy\n",
    "\n",
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "black  = np.where(protected_test == 1)[0] # African American\n",
    "white  = np.where(protected_test == 0)[0] # Caucasian \n",
    "accuracy.append(log_reg.score(X_test, y_test))\n",
    "calibration.append(log_reg.score(X_test[black], y_test[black]) - log_reg.score(X_test[white], y_test[white]))\n",
    "\n",
    "# Test impact of each feature on model\n",
    "for i in range(X_train.shape[1]):\n",
    "    features = list(range(X_train.shape[1]))\n",
    "    features.pop(i)\n",
    "    X_train_subset = X_train[:, features]\n",
    "    X_test_subset = X_test[:, features]\n",
    "    \n",
    "    log_reg = LogisticRegression()\n",
    "    log_reg.fit(X_train_subset, y_train)\n",
    "    acc_subset = log_reg.score(X_test_subset, y_test)\n",
    "    cal_subset = log_reg.score(X_test_subset[black],\n",
    "                               y_test[black]) - log_reg.score(X_test_subset[white],\n",
    "                                                              y_test[white])\n",
    "    \n",
    "    accuracy.append(acc_subset)\n",
    "    calibration.append(cal_subset)\n",
    "    \n",
    "\n",
    "col_names = [\"None\", \"Sex\", \"Age\", \"Prior Count\", \"Charge Degree\", \"Length of stay\"]\n",
    "accuracy = [x * 100 for x in accuracy]\n",
    "calibration = [x * 100 for x in calibration]\n",
    "analysis = pd.DataFrame(list(zip(col_names, accuracy, calibration)),\n",
    "                          columns=[\"Eliminating Feature\", \"Accuracy (%)\", \"Calibration (%)\"])\n",
    "analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af2f9bb6",
   "metadata": {},
   "source": [
    "It can be observed that eliminating Prior count results in the strongest drop in accuracy despite it's high discrimatory effect. We also see that age has a significant drop in accuracy despite its high discrimatory effect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c20021",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
